{
    "name": "r-randomforest",
    "aliases": [],
    "versions": [
        {
            "name": "4.6-14",
            "sha256": "f4b88920419eb0a89d0bc5744af0416d92d112988702dc726882394128a8754d"
        },
        {
            "name": "4.6-12",
            "sha256": "6e512f8f88a51c01a918360acba61f1f39432f6e690bc231b7864218558b83c4"
        }
    ],
    "latest_version": "4.6-14",
    "build_system": "RPackage",
    "conflicts": [],
    "variants": [],
    "homepage": "https://cloud.r-project.org/package=randomForest",
    "maintainers": [
        "glennpj"
    ],
    "patches": [],
    "resources": [],
    "description": "Breiman and Cutler's Random Forests for Classification and Regression.\nClassification and regression based on a forest of trees using random\ninputs.\n",
    "dependencies": [
        {
            "name": "r",
            "description": "R is 'GNU S', a freely available language and environment for\nstatistical computing and graphics which provides a wide variety of\nstatistical and graphical techniques: linear and nonlinear modelling,\nstatistical tests, time series analysis, classification, clustering,\netc. Please consult the R project homepage for further information."
        }
    ],
    "dependent_to": [
        {
            "name": "r-condop",
            "description": "Condition-Dependent Operon Predictions. An implementation of the\ncomputational strategy for the comprehensive analysis of condition-\ndependent operon maps in prokaryotes proposed by Fortino et al. (2014)\n<doi:10.1186/1471-2105-15-145>. It uses RNA-seq transcriptome profiles\nto improve prokaryotic operon map inference."
        },
        {
            "name": "r-rminer",
            "description": "Data Mining Classification and Regression Methods. Facilitates the use\nof data mining algorithms in classification and regression (including\ntime series forecasting) tasks by presenting a short and coherent set of\nfunctions. Versions: 1.4.6 / 1.4.5 / 1.4.4 new automated machine\nlearning (AutoML) and ensembles, via improved fit(), mining() and\nmparheuristic() functions, and new categorical preprocessing, via\nimproved delevels() function; 1.4.3 new metrics (e.g., macro precision,\nexplained variance), new \"lssvm\" model and improved mparheuristic()\nfunction; 1.4.2 new \"NMAE\" metric, \"xgboost\" and \"cv.glmnet\" models (16\nclassification and 18 regression models); 1.4.1 new tutorial and more\nrobust version; 1.4 - new classification and regression models, with a\ntotal of 14 classification and 15 regression methods, including:\nDecision Trees, Neural Networks, Support Vector Machines, Random\nForests, Bagging and Boosting; 1.3 and 1.3.1 - new classification and\nregression metrics; 1.2 - new input importance methods via improved\nImportance() function; 1.0 - first version."
        },
        {
            "name": "r-varselrf",
            "description": "Variable Selection using Random Forests. Variable selection from random\nforests using both backwards variable elimination (for the selection of\nsmall sets of non-redundant variables) and selection based on the\nimportance spectrum (somewhat similar to scree plots; for the selection\nof large, potentially highly-correlated variables). Main applications in\nhigh-dimensional data (e.g., microarray data, and other genomics and\nproteomics applications)."
        }
    ]
}