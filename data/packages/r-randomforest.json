{
    "name": "r-randomforest",
    "aliases": [],
    "versions": [
        {
            "name": "4.6-14",
            "sha256": "f4b88920419eb0a89d0bc5744af0416d92d112988702dc726882394128a8754d"
        },
        {
            "name": "4.6-12",
            "sha256": "6e512f8f88a51c01a918360acba61f1f39432f6e690bc231b7864218558b83c4"
        }
    ],
    "build_system": "RPackage",
    "conflicts": [],
    "variants": [],
    "homepage": "https://www.stat.berkeley.edu/~breiman/RandomForests/",
    "maintainers": [
        "glennpj"
    ],
    "patches": [],
    "resources": [],
    "description": "Classification and regression based on a forest of trees using random\ninputs.\n",
    "dependencies": [
        {
            "name": "r",
            "description": "R is 'GNU S', a freely available language and environment for\nstatistical computing and graphics which provides a wide variety of\nstatistical and graphical techniques: linear and nonlinear modelling,\nstatistical tests, time series analysis, classification, clustering,\netc. Please consult the R project homepage for further information."
        }
    ],
    "dependent_to": [
        {
            "name": "r-condop",
            "description": "CONDOP: Condition-Dependent Operon Predictions. An implementation of the\ncomputational strategy for the comprehensive analysis of condition-\ndependent operon maps in prokaryotes proposed by Fortino et al. (2014)\n<doi:10.1186/1471-2105-15-145>. It uses RNA-seq transcriptome profiles\nto improve prokaryotic operon map inference."
        },
        {
            "name": "r-rminer",
            "description": "Data Mining Classification and Regression Methods Facilitates the use of\ndata mining algorithms in classification and regression (including time\nseries forecasting) tasks by presenting a short and coherent set of\nfunctions. Versions: 1.4.6 / 1.4.5 / 1.4.4 new automated machine\nlearning (AutoML) and ensembles, via improved fit(), mining() and\nmparheuristic() functions, and new categorical preprocessing, via\nimproved delevels() function; 1.4.3 new metrics (e.g., macro precision,\nexplained variance), new \"lssvm\" model and improved mparheuristic()\nfunction; 1.4.2 new \"NMAE\" metric, \"xgboost\" and \"cv.glmnet\" models (16\nclassification and 18 regression models); 1.4.1 new tutorial and more\nrobust version; 1.4 - new classification and regression models, with a\ntotal of 14 classification and 15 regression methods, including:\nDecision Trees, Neural Networks, Support Vector Machines, Random\nForests, Bagging and Boosting; 1.3 and 1.3.1 - new classification and\nregression metrics; 1.2 - new input importance methods via improved\nImportance() function; 1.0 - first version."
        },
        {
            "name": "r-varselrf",
            "description": "Variable selection from random forests using both backwards variable\nelimination (for the selection of small sets of non-redundant variables)\nand selection based on the importance spectrum (somewhat similar to\nscree plots; for the selection of large, potentially highly-correlated\nvariables) . Main applications in high-dimensional data (e.g.,\nmicroarray data, and other genomics and proteomics applications)."
        }
    ]
}