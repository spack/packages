{
    "name": "py-pandas",
    "aliases": [],
    "versions": [
        {
            "name": "1.4.2",
            "sha256": "92bc1fc585f1463ca827b45535957815b7deb218c549b7c18402c322c7549a12"
        },
        {
            "name": "1.4.1",
            "sha256": "8db93ec98ac7cb5f8ac1420c10f5e3c43533153f253fe7fb6d891cf5aa2b80d2"
        },
        {
            "name": "1.4.0",
            "sha256": "cdd76254c7f0a1583bd4e4781fb450d0ebf392e10d3f12e92c95575942e37df5"
        },
        {
            "name": "1.3.5",
            "sha256": "1e4285f5de1012de20ca46b188ccf33521bff61ba5c5ebd78b4fb28e5416a9f1"
        },
        {
            "name": "1.3.4",
            "sha256": "a2aa18d3f0b7d538e21932f637fbfe8518d085238b429e4790a35e1e44a96ffc"
        },
        {
            "name": "1.3.3",
            "sha256": "272c8cb14aa9793eada6b1ebe81994616e647b5892a370c7135efb2924b701df"
        },
        {
            "name": "1.3.2",
            "sha256": "cbcb84d63867af3411fa063af3de64902665bb5b3d40b25b2059e40603594e87"
        },
        {
            "name": "1.3.1",
            "sha256": "341935a594db24f3ff07d1b34d1d231786aa9adfa84b76eab10bf42907c8aed3"
        },
        {
            "name": "1.3.0",
            "sha256": "c554e6c9cf2d5ea1aba5979cc837b3649539ced0e18ece186f055450c86622e2"
        },
        {
            "name": "1.2.5",
            "sha256": "14abb8ea73fce8aebbb1fb44bec809163f1c55241bcc1db91c2c780e97265033"
        },
        {
            "name": "1.2.4",
            "sha256": "649ecab692fade3cbfcf967ff936496b0cfba0af00a55dfaacd82bdda5cb2279"
        },
        {
            "name": "1.2.3",
            "sha256": "df6f10b85aef7a5bb25259ad651ad1cc1d6bb09000595cab47e718cbac250b1d"
        },
        {
            "name": "1.2.2",
            "sha256": "14ed84b463e9b84c8ff9308a79b04bf591ae3122a376ee0f62c68a1bd917a773"
        },
        {
            "name": "1.2.1",
            "sha256": "5527c5475d955c0bc9689c56865aaa2a7b13c504d6c44f0aadbf57b565af5ebd"
        },
        {
            "name": "1.2.0",
            "sha256": "e03386615b970b8b41da6a68afe717626741bb2431cec993640685614c0680e4"
        },
        {
            "name": "1.1.5",
            "sha256": "f10fc41ee3c75a474d3bdf68d396f10782d013d7f67db99c0efbfd0acb99701b"
        },
        {
            "name": "1.1.4",
            "sha256": "a979d0404b135c63954dea79e6246c45dd45371a88631cdbb4877d844e6de3b6"
        },
        {
            "name": "1.1.3",
            "sha256": "babbeda2f83b0686c9ad38d93b10516e68cdcd5771007eb80a763e98aaf44613"
        },
        {
            "name": "1.1.2",
            "sha256": "b64ffd87a2cfd31b40acd4b92cb72ea9a52a48165aec4c140e78fd69c45d1444"
        },
        {
            "name": "1.1.1",
            "sha256": "53328284a7bb046e2e885fd1b8c078bd896d7fc4575b915d4936f54984a2ba67"
        },
        {
            "name": "1.1.0",
            "sha256": "b39508562ad0bb3f384b0db24da7d68a2608b9ddc85b1d931ccaaa92d5e45273"
        },
        {
            "name": "1.0.5",
            "sha256": "69c5d920a0b2a9838e677f78f4dde506b95ea8e4d30da25859db6469ded84fa8"
        },
        {
            "name": "1.0.4",
            "sha256": "b35d625282baa7b51e82e52622c300a1ca9f786711b2af7cbe64f1e6831f4126"
        },
        {
            "name": "1.0.3",
            "sha256": "32f42e322fb903d0e189a4c10b75ba70d90958cc4f66a1781ed027f1a1d14586"
        },
        {
            "name": "1.0.2",
            "sha256": "76334ba36aa42f93b6b47b79cbc32187d3a178a4ab1c3a478c8f4198bcd93a73"
        },
        {
            "name": "1.0.1",
            "sha256": "3c07765308f091d81b6735d4f2242bb43c332cc3461cae60543df6b10967fe27"
        },
        {
            "name": "1.0.0",
            "sha256": "3ea6cc86931f57f18b1240572216f09922d91b19ab8a01cf24734394a3db3bec"
        },
        {
            "name": "0.25.3",
            "sha256": "52da74df8a9c9a103af0a72c9d5fdc8e0183a90884278db7f386b5692a2220a4"
        },
        {
            "name": "0.25.2",
            "sha256": "ca91a19d1f0a280874a24dca44aadce42da7f3a7edb7e9ab7c7baad8febee2be"
        },
        {
            "name": "0.25.1",
            "sha256": "cb2e197b7b0687becb026b84d3c242482f20cbb29a9981e43604eb67576da9f6"
        },
        {
            "name": "0.25.0",
            "sha256": "914341ad2d5b1ea522798efa4016430b66107d05781dbfe7cf05eba8f37df995"
        },
        {
            "name": "0.24.2",
            "sha256": "4f919f409c433577a501e023943e582c57355d50a724c589e78bc1d551a535a2"
        },
        {
            "name": "0.24.1",
            "sha256": "435821cb2501eabbcee7e83614bd710940dc0cf28b5afbc4bdb816c31cec71af"
        },
        {
            "name": "0.23.4",
            "sha256": "5b24ca47acf69222e82530e89111dd9d14f9b970ab2cd3a1c2c78f0c4fbba4f4"
        },
        {
            "name": "0.21.1",
            "sha256": "c5f5cba88bf0659554c41c909e1f78139f6fce8fa9315a29a23692b38ff9788a"
        },
        {
            "name": "0.20.0",
            "sha256": "54f7a2bb2a7832c0446ad51d779806f07ec4ea2bb7c9aea4b83669fa97e778c4"
        },
        {
            "name": "0.19.2",
            "sha256": "6f0f4f598c2b16746803c8bafef7c721c57e4844da752d36240c0acf97658014"
        },
        {
            "name": "0.19.0",
            "sha256": "4697606cdf023c6b7fcb74e48aaf25cf282a1a00e339d2d274cf1b663748805b"
        },
        {
            "name": "0.18.0",
            "sha256": "c975710ce8154b50f39a46aa3ea88d95b680191d1d9d4b5dd91eae7215e01814"
        },
        {
            "name": "0.16.1",
            "sha256": "570d243f8cb068bf780461b9225d2e7bef7c90aa10d43cf908fe541fc92df8b6"
        },
        {
            "name": "0.16.0",
            "sha256": "4013de6f8796ca9d2871218861823bd9878a8dfacd26e08ccf9afdd01bbad9f1"
        }
    ],
    "latest_version": "1.4.2",
    "build_system": "PythonPackage",
    "conflicts": [],
    "variants": [],
    "homepage": "https://pandas.pydata.org/",
    "maintainers": [
        "adamjstewart"
    ],
    "patches": [],
    "resources": [],
    "description": "pandas is a fast, powerful, flexible and easy to use open source data\nanalysis and manipulation tool, built on top of the Python programming\nlanguage.\n",
    "dependencies": [
        {
            "name": "python",
            "description": "The Python programming language."
        },
        {
            "name": "py-pip",
            "description": "The PyPA recommended tool for installing Python packages."
        },
        {
            "name": "py-wheel",
            "description": "A built-package format for Python."
        },
        {
            "name": "py-cython",
            "description": "The Cython compiler for writing C extensions for the Python language."
        },
        {
            "name": "py-setuptools",
            "description": "A Python utility that aids in the process of downloading, building,\nupgrading, installing, and uninstalling Python packages."
        },
        {
            "name": "py-numpy",
            "description": "NumPy is the fundamental package for scientific computing with Python.\nIt contains among other things: a powerful N-dimensional array object,\nsophisticated (broadcasting) functions, tools for integrating C/C++ and\nFortran code, and useful linear algebra, Fourier transform, and random\nnumber capabilities"
        },
        {
            "name": "py-python-dateutil",
            "description": "Extensions to the standard Python datetime module."
        },
        {
            "name": "py-pytz",
            "description": "World timezone definitions, modern and historical."
        },
        {
            "name": "py-numexpr",
            "description": "Fast numerical expression evaluator for NumPy"
        },
        {
            "name": "py-bottleneck",
            "description": "A collection of fast NumPy array functions written in Cython."
        }
    ],
    "dependent_to": [
        {
            "name": "py-mizani",
            "description": "Mizani is a scales package for graphics. It is based on Hadley Wickham's\nScales package."
        },
        {
            "name": "py-lifelines",
            "description": "Survival analysis was originally developed and applied heavily by the\nactuarial and medical community. Its purpose was to answer *why do\nevents occur now versus later* under uncertainty (where *events* might\nrefer to deaths, disease remission, etc.). *lifelines* is a pure Python\nimplementation of the best parts of survival analysis."
        },
        {
            "name": "geopm",
            "description": "GEOPM is an extensible power management framework targeting HPC. The\nGEOPM package provides libgeopm, libgeopmpolicy and applications\ngeopmctl and geopmpolicy, as well as tools for postprocessing. GEOPM is\ndesigned to be extended for new control algorithms and new hardware\npower management features via its plugin infrastructure. Note: GEOPM\ninterfaces with hardware using Model Specific Registers (MSRs). For\npropper usage make sure MSRs are made available directly or via the msr-\nsafe kernel module by your administrator."
        },
        {
            "name": "py-torch-geometric",
            "description": "PyTorch Geometric (PyG) is a geometric deep learning extension library\nfor PyTorch. It consists of various methods for deep learning on graphs\nand other irregular structures, also known as geometric deep learning,\nfrom a variety of published papers. In addition, it consists of an easy-\nto-use mini-batch loader for many small and single giant graphs, multi\ngpu-support, a large number of common benchmark datasets (based on\nsimple interfaces to create your own), and helpful transforms, both for\nlearning on arbitrary graphs as well as on 3D meshes or point clouds."
        },
        {
            "name": "py-deepecho",
            "description": "DeepEcho is a Synthetic Data Generation Python library for mixed-type,\nmultivariate time series."
        },
        {
            "name": "openturns",
            "description": "OpenTURNS is a scientific C++ and Python library featuring an internal\ndata model and algorithms dedicated to the treatment of uncertainties.\nThe main goal of this library is to provide all functionalities needed\nto treat uncertainties in studies with industrial applications. Targeted\nusers are all engineers who want to introduce the probabilistic\ndimension in their so far deterministic studies."
        },
        {
            "name": "py-dp-gp-cluster",
            "description": "DP_GP_cluster clusters genes by expression over a time course using a\nDirichlet process Gaussian process model."
        },
        {
            "name": "py-fastai",
            "description": "You can use fastai without any installation by using Google Colab. In\nfact, every page of this documentation is also available as an\ninteractive notebook - click \"Open in colab\" at the top of any page to\nopen it (be sure to change the Colab runtime to \"GPU\" to have it run\nfast!) See the fast.ai documentation on Using Colab for more\ninformation."
        },
        {
            "name": "py-cnvkit",
            "description": "Copy number variation toolkit for high-throughput sequencing."
        },
        {
            "name": "py-openmc",
            "description": "OpenMC is a community-developed Monte Carlo neutron and photon transport\nsimulation code. It is capable of performing fixed source, k-eigenvalue,\nand subcritical multiplication calculations on models built using either\na constructive solid geometry or CAD representation. OpenMC supports\nboth continuous-energy and multigroup transport. The continuous-energy\nparticle interaction data is based on a native HDF5 format that can be\ngenerated from ACE files produced by NJOY. Parallelism is enabled via a\nhybrid MPI and OpenMP programming model."
        },
        {
            "name": "py-statsmodels",
            "description": "Statistical computations and models for use with SciPy"
        },
        {
            "name": "py-devlib",
            "description": "Library for interaction with and instrumentation of remote devices."
        },
        {
            "name": "py-pybobyqa",
            "description": "Py-BOBYQA is a flexible package for solving bound-constrained general\nobjective minimization, without requiring derivatives of the objective."
        },
        {
            "name": "py-elephant",
            "description": "Elephant is a package for analysis of electrophysiology data in Python"
        },
        {
            "name": "py-ucsf-pyem",
            "description": "UCSF pyem is a collection of Python modules and command-line utilities\nfor electron microscopy of biological samples."
        },
        {
            "name": "py-torchgeo",
            "description": "TorchGeo: datasets, transforms, and models for geospatial data. TorchGeo\nis a PyTorch domain library, similar to torchvision, that provides\ndatasets, transforms, samplers, and pre-trained models specific to\ngeospatial data."
        },
        {
            "name": "gptune",
            "description": "GPTune is an autotuning framework that relies on multitask and transfer\nlearnings to help solve the underlying black-box optimization problem\nusing Bayesian optimization methodologies."
        },
        {
            "name": "partitionfinder",
            "description": "PartitionFinder is free open source software to select best-fit\npartitioning schemes and models of molecular evolution for phylogenetic\nanalyses."
        },
        {
            "name": "py-cinemasci",
            "description": "A set of python tools for reading, writing and viewing Cinema databases"
        },
        {
            "name": "py-nistats",
            "description": "Modeling and Statistical analysis of fMRI data in Python."
        },
        {
            "name": "py-petastorm",
            "description": "Petastorm is a library enabling the use of Parquet storage from\nTensorflow, Pytorch, and other Python-based ML training frameworks."
        },
        {
            "name": "py-seaborn",
            "description": "Seaborn: statistical data visualization. Seaborn is a library for making\nattractive and informative statistical graphics in Python. It is built\non top of matplotlib and tightly integrated with the PyData stack,\nincluding support for numpy and pandas data structures and statistical\nroutines from scipy and statsmodels."
        },
        {
            "name": "cosmomc",
            "description": "CosmoMC is a Fortran 2008 Markov-Chain Monte-Carlo (MCMC) engine for\nexploring cosmological parameter space, together with Fortran and python\ncode for analysing Monte-Carlo samples and importance sampling (plus a\nsuite of scripts for building grids of runs, plotting and presenting\nresults)."
        },
        {
            "name": "py-biopandas",
            "description": "Working with molecular structures in pandas DataFrames"
        },
        {
            "name": "callflow",
            "description": "CallFlow is an interactive visual analysis tool that provides a high-\nlevel overview of CCTs together with semantic refinement operations to\nprogressively explore the CCTs."
        },
        {
            "name": "py-nilearn",
            "description": "Statistical learning for neuroimaging in Python."
        },
        {
            "name": "survey",
            "description": "Survey is a high level performance tool product from Trenza, Inc. The\nsurvey collector/analytics framework is a new generation, high level,\nlightweight multiplatform Linux tool set that targets metric collection\nfor high level performance analysis of applications running on both\nsingle node and on large scale platforms, including the Cray platforms.\nThe collector is designed to work on sequential, MPI, OpenMP, and hybrid\ncodes and directly leverages several interfaces available for tools\ninside current MPI implementations including: MPICH, MVAPICH, MPT, and\nOpenMPI. It also supports multiple architectures and has been tested on\nmachines based on Intel, AMD, ARM, and IBM P8/9 processors and\nintegrated GPUs. Survey is a licensed product with the source not openly\navailable. To access the survey source and build with spack please\ncontact: Trenza Inc. via: dmont@trenzasynergy.com or\njeg@trenzasynergy.com"
        },
        {
            "name": "portcullis",
            "description": "PORTable CULLing of Invalid Splice junctions"
        },
        {
            "name": "py-geoplot",
            "description": "geoplot is a high-level Python geospatial plotting library. It's an\nextension to cartopy and matplotlib which makes mapping easy: like\nseaborn for geospatial."
        },
        {
            "name": "py-nibetaseries",
            "description": "BetaSeries Correlations implemented in Nipype."
        },
        {
            "name": "py-hep-ml",
            "description": "Machine Learning for High Energy Physics"
        },
        {
            "name": "py-rdt",
            "description": "RDT is a Python library used to transform data for data science\nlibraries and preserve the transformations in order to revert them as\nneeded."
        },
        {
            "name": "py-pipits",
            "description": "Automated pipeline for analyses of fungal ITS from the Illumina"
        },
        {
            "name": "py-pybids",
            "description": "bids: interface with datasets conforming to BIDS"
        },
        {
            "name": "py-correctionlib",
            "description": "A generic correction library"
        },
        {
            "name": "py-abipy",
            "description": "Python package to automate ABINIT calculations and analyze the results."
        },
        {
            "name": "py-geopandas",
            "description": "GeoPandas is an open source project to make working with geospatial data\nin python easier. GeoPandas extends the datatypes used by pandas to\nallow spatial operations on geometric types. Geometric operations are\nperformed by shapely. Geopandas further depends on fiona for file access\nand descartes and matplotlib for plotting."
        },
        {
            "name": "py-umi-tools",
            "description": "Tools for handling Unique Molecular Identifiers in NGS data sets"
        },
        {
            "name": "py-mixedhtseq",
            "description": "HTSeq for mixed single and paired end reads"
        },
        {
            "name": "py-neurokit2",
            "description": "The Python Toolbox for Neurophysiological Signal Processing. This\npackage is the continuation of NeuroKit 1. It's a user-friendly package\nproviding easy access to advanced biosignal processing routines.\nResearchers and clinicians without extensive knowledge of programming or\nbiomedical signal processing can analyze physiological data with only\ntwo lines of code."
        },
        {
            "name": "py-motmetrics",
            "description": "The py-motmetrics library provides a Python implementation of metrics\nfor benchmarking multiple object trackers (MOT)."
        },
        {
            "name": "py-dask-ml",
            "description": "Scalable Machine Learning with Dask."
        },
        {
            "name": "py-hypothesis",
            "description": "A library for property based testing."
        },
        {
            "name": "py-goatools",
            "description": "Python scripts to find enrichment of GO terms"
        },
        {
            "name": "py-workload-automation",
            "description": "Workload Automation (WA) is a framework for executing workloads and\ncollecting measurements on Android and Linux devices."
        },
        {
            "name": "py-arviz",
            "description": "ArviZ (pronounced \"AR-vees\") is a Python package for exploratory\nanalysis of Bayesian models. Includes functions for posterior analysis,\nmodel checking, comparison and diagnostics."
        },
        {
            "name": "py-copulas",
            "description": "Copulas is a Python library for modeling multivariate distributions and\nsampling from them using copula functions. Given a table containing\nnumerical data, we can use Copulas to learn the distribution and later\non generate new synthetic rows following the same statistical\nproperties."
        },
        {
            "name": "py-niworkflows",
            "description": "Common workflows for MRI (anatomical, functional, diffusion, etc)"
        },
        {
            "name": "py-arcgis",
            "description": "ArcGIS API for Python."
        },
        {
            "name": "py-xgboost",
            "description": "XGBoost is an optimized distributed gradient boosting library designed\nto be highly efficient, flexible and portable."
        },
        {
            "name": "hicops",
            "description": "HiCOPS is a software framework for accelerating database peptide search\nworkflows on supercomputers. HiCOPS provided algorithm-independent\nparallelizations and optimizations can be extended into new HPC database\nsearch algorithms or scalably accelerate the existing ones."
        },
        {
            "name": "py-cudf",
            "description": "Built based on the Apache Arrow columnar memory format, cuDF is a GPU\nDataFrame library for loading, joining, aggregating, filtering, and\notherwise manipulating data."
        },
        {
            "name": "py-formulaic",
            "description": "Formulaic is a high-performance implementation of Wilkinson formulas for\nPython."
        },
        {
            "name": "py-convokit",
            "description": "This toolkit contains tools to extract conversational features and\nanalyze social phenomena in conversations, using a single unified\ninterface inspired by (and compatible with) scikit-learn."
        },
        {
            "name": "py-wub",
            "description": "Bioinformatics tools and a software library developed by the Oxford\nNanopore Technologies Applications group."
        },
        {
            "name": "py-astropy",
            "description": "The Astropy Project is a community effort to develop a single core\npackage for Astronomy in Python and foster interoperability between\nPython astronomy packages."
        },
        {
            "name": "py-sdmetrics",
            "description": "The SDMetrics library provides a set of dataset-agnostic tools for\nevaluating the quality of a synthetic database by comparing it to the\nreal database that it is modeled after."
        },
        {
            "name": "py-damask",
            "description": "Pre- and post-processing tools for DAMASK"
        },
        {
            "name": "py-mapclassify",
            "description": "Classification Schemes for Choropleth Maps."
        },
        {
            "name": "py-gemini",
            "description": "GEMINI (GEnome MINIng) is a flexible framework for exploring genetic\nvariation in the context of the wealth of genome annotations available\nfor the human genome."
        },
        {
            "name": "py-xarray",
            "description": "N-D labeled arrays and datasets in Python"
        },
        {
            "name": "py-rnacocktail",
            "description": "RNACocktail: A comprehensive framework for accurate and efficient RNA-\nSeq analysis."
        },
        {
            "name": "py-pymatgen",
            "description": "Python Materials Genomics is a robust materials analysis code that\ndefines core object representations for structures and molecules with\nsupport for many electronic structure codes. It is currently the core\nanalysis code powering the Materials Project."
        },
        {
            "name": "py-deepsig",
            "description": "deep-significance: Easy and Better Significance Testing for Deep Neural\nNetworks"
        },
        {
            "name": "mlperf-deepcam",
            "description": "PyTorch implementation for the climate segmentation benchmark, based on\nthe Exascale Deep Learning for Climate Analytics"
        },
        {
            "name": "py-sdv",
            "description": "The Synthetic Data Vault (SDV) is a Synthetic Data Generation ecosystem\nof libraries that allows users to easily learn single-table, multi-table\nand timeseries datasets to later on generate new Synthetic Data that has\nthe same format and statistical properties as the original dataset."
        },
        {
            "name": "py-salib",
            "description": "Python implementations of commonly used sensitivity analysis methods."
        },
        {
            "name": "amr-wind",
            "description": "AMR-Wind is a massively parallel, block-structured adaptive-mesh,\nincompressible flow sover for wind turbine and wind farm simulations."
        },
        {
            "name": "py-mne",
            "description": "MNE python project for MEG and EEG data analysis."
        },
        {
            "name": "py-ctgan",
            "description": "CTGAN is a collection of Deep Learning based Synthetic Data Generators\nfor single table data, which are able to learn from real data and\ngenerate synthetic clones with high fidelity."
        },
        {
            "name": "py-crispresso",
            "description": "Software pipeline for the analysis of CRISPR-Cas9 genome editing\noutcomes from deep sequencing data."
        },
        {
            "name": "py-plotnine",
            "description": "plotnine is an implementation of a grammar of graphics in Python, it is\nbased on ggplot2. The grammar allows users to compose plots by\nexplicitly mapping data to the visual objects that make up the plot."
        },
        {
            "name": "py-datasets",
            "description": "Datasets is a lightweight library providing two main features: one-line\ndataloaders for many public datasets and efficient data pre-processing."
        },
        {
            "name": "py-scikit-learn",
            "description": "A set of python modules for machine learning and data mining."
        },
        {
            "name": "py-metpy",
            "description": "Collection of tools for reading, visualizing and performing calculations\nwith weather data."
        },
        {
            "name": "py-pymc3",
            "description": "PyMC3 is a Python package for Bayesian statistical modeling and\nProbabilistic Machine Learning focusing on advanced Markov chain Monte\nCarlo (MCMC) and variational inference (VI) algorithms. Its flexibility\nand extensibility make it applicable to a large suite of problems."
        },
        {
            "name": "py-tpot",
            "description": "A Python Automated Machine Learning tool that optimizes machine\nlearning pipelines using genetic programming."
        },
        {
            "name": "cosmoflow-benchmark",
            "description": "This is a an implementation of the CosmoFlow 3D convolutional neural\nnetwork for benchmarking. It is written in TensorFlow with the Keras API\nand uses Horovod for distributed training."
        },
        {
            "name": "cradl",
            "description": "The CRADL proxy application captured performance metrics during\ninference on data from multiphysics codes, specifically ALE\nhydrodynamics codes."
        },
        {
            "name": "py-inference-schema",
            "description": "This package is intended to provide a uniform schema for common machine\nlearning applications, as well as a set of decorators that can be used\nto aid in web based ML prediction applications."
        },
        {
            "name": "py-biom-format",
            "description": "The BIOM file format (canonically pronounced biome) is designed to be a\ngeneral-use format for representing biological sample by observation\ncontingency tables."
        },
        {
            "name": "reditools",
            "description": "REDItools: python scripts for RNA editing detection by RNA-Seq data.\nREDItools are simple python scripts conceived to facilitate the\ninvestigation of RNA editing at large-scale and devoted to research\ngroups that would to explore such phenomenon in own data but don't have\nsufficient bioinformatics skills. They work on main operating systems\n(although unix/linux-based OS are preferred), can handle reads from\nwhatever platform in the standard BAM format and implement a variety of\nfilters."
        },
        {
            "name": "paraview",
            "description": "ParaView is an open-source, multi-platform data analysis and\nvisualization application. This package includes the Catalyst in-situ\nlibrary for versions 5.7 and greater, otherwise use the catalyst\npackage."
        },
        {
            "name": "py-dh-scikit-optimize",
            "description": "A Modified version of scikit-optimize a Sequential model-based\noptimization toolbox for DeepHyper. Scikit-Optimize, or skopt, is a\nsimple and efficient library to minimize (very) expensive and noisy\nblack-box functions. It implements several methods for sequential model-\nbased optimization. skopt aims to be accessible and easy to use in many\ncontexts. The library is built on top of NumPy, SciPy and Scikit-Learn."
        },
        {
            "name": "py-geeup",
            "description": "Simple Client for Earth Engine Uploads with Selenium Support."
        },
        {
            "name": "py-hatchet",
            "description": "Hatchet is a performance tool for analyzing hierarchical performance\ndata using a graph-indexed Pandas dataframe."
        },
        {
            "name": "py-datalad-neuroimaging",
            "description": "DataLad extension package for neuro/medical imaging"
        },
        {
            "name": "parsec",
            "description": "PaRSEC: the Parallel Runtime Scheduler and Execution Controller PaRSEC\nis a runtime and a programming toolbox that support the design and\nparallel execution of micro-tasks on distributed, heterogeneous systems."
        },
        {
            "name": "py-pauvre",
            "description": "pauvre: plotting package designed for nanopore and PacBio long reads"
        },
        {
            "name": "py-mlxtend",
            "description": "Mlxtend (machine learning extensions) is a Python library of useful\ntools for the day-to-day data science tasks."
        },
        {
            "name": "py-pyani",
            "description": "pyani is a Python3 module that provides support for calculating average\nnucleotide identity (ANI) and related measures for whole genome\ncomparisons, and rendering relevant graphical summary output. Where\navailable, it takes advantage of multicore systems, and can integrate\nwith SGE/OGE-type job schedulers for the sequence comparisons."
        },
        {
            "name": "py-dask",
            "description": "Dask is a flexible parallel computing library for analytics."
        },
        {
            "name": "timemory",
            "description": "Modular profiling toolkit and suite of libraries and tools for\nC/C++/Fortran/CUDA/Python"
        },
        {
            "name": "py-pybedtools",
            "description": "Python wrapper -- and more -- for Aaron Quinlan's BEDTools"
        },
        {
            "name": "py-labours",
            "description": "Python module dependency visualization."
        },
        {
            "name": "py-carputils",
            "description": "The carputils framework for running simulations with the openCARP\nsoftware."
        }
    ]
}