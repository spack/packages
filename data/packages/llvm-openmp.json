{
    "name": "llvm-openmp",
    "aliases": [],
    "versions": [
        {
            "name": "12.0.1",
            "sha256": "60fe79440eaa9ebf583a6ea7f81501310388c02754dbe7dc210776014d06b091"
        },
        {
            "name": "9.0.0",
            "sha256": "9979eb1133066376cc0be29d1682bc0b0e7fb541075b391061679111ae4d3b5b"
        },
        {
            "name": "8.0.0",
            "sha256": "f7b1705d2f16c4fc23d6531f67d2dd6fb78a077dd346b02fed64f4b8df65c9d5"
        }
    ],
    "latest_version": "12.0.1",
    "build_system": "CMakePackage",
    "conflicts": [
        {
            "name": "+ipo",
            "spec": "^cmake@:3.8",
            "description": "+ipo is not supported by CMake < 3.9"
        }
    ],
    "variants": [
        {
            "name": "build_type",
            "default": "RelWithDebInfo",
            "description": "CMake build type"
        },
        {
            "name": "ipo",
            "default": false,
            "description": "CMake interprocedural optimization"
        },
        {
            "name": "multicompat",
            "default": false,
            "description": "Support gomp and the Intel openMP runtime library."
        }
    ],
    "homepage": "https://openmp.llvm.org/",
    "maintainers": [],
    "patches": [],
    "resources": [],
    "description": "The OpenMP subproject of LLVM contains the components required to build\nan executable OpenMP program that are outside the compiler itself.\n",
    "dependencies": [
        {
            "name": "cmake",
            "description": "A cross-platform, open-source build system. CMake is a family of tools\ndesigned to build, test and package software."
        }
    ],
    "dependent_to": [
        {
            "name": "hipace",
            "description": "Highly efficient Plasma Accelerator Emulation, quasistatic particle-in-\ncell code"
        },
        {
            "name": "fujitsu-fftw",
            "description": "FFTW (Fujitsu Optimized version) is a comprehensive collection of fast C\nroutines for computing the Discrete Fourier Transform (DFT) and various\nspecial cases thereof. It is an open-source implementation of the Fast\nFourier transform algorithm. It can compute transforms of real and\ncomplex-values arrays of arbitrary size and dimension. Fujitsu Optimized\nFFTW is the optimized FFTW implementation targeted for A64FX CPUs. For\nsingle precision build, please use precision value as float. Example :\nspack install fujitsufftw precision=float"
        },
        {
            "name": "amdfftw",
            "description": "FFTW (AMD Optimized version) is a comprehensive collection of fast C\nroutines for computing the Discrete Fourier Transform (DFT) and various\nspecial cases thereof. It is an open-source implementation of the Fast\nFourier transform algorithm. It can compute transforms of real and\ncomplex-values arrays of arbitrary size and dimension. AMD Optimized\nFFTW is the optimized FFTW implementation targeted for AMD CPUs. For\nsingle precision build, please use precision value as float. Example :\nspack install amdfftw precision=float"
        },
        {
            "name": "hydrogen",
            "description": "Hydrogen: Distributed-memory dense and sparse-direct linear algebra and\noptimization library. Based on the Elemental library."
        },
        {
            "name": "py-dgl",
            "description": "Deep Graph Library (DGL). DGL is an easy-to-use, high performance and\nscalable Python package for deep learning on graphs. DGL is framework\nagnostic, meaning if a deep graph model is a component of an end-to-end\napplication, the rest of the logics can be implemented in any major\nframeworks, such as PyTorch, Apache MXNet or TensorFlow."
        },
        {
            "name": "fftw",
            "description": "FFTW is a C subroutine library for computing the discrete Fourier\ntransform (DFT) in one or more dimensions, of arbitrary input size, and\nof both real and complex data (as well as of even/odd data, i.e. the\ndiscrete cosine/sine transforms or DCT/DST). We believe that FFTW, which\nis free software, should become the FFT library of choice for most\napplications."
        },
        {
            "name": "dihydrogen",
            "description": "DiHydrogen is the second version of the Hydrogen fork of the well-known\ndistributed linear algebra library, Elemental. DiHydrogen aims to be a\nbasic distributed multilinear algebra interface with a particular\nemphasis on the needs of the distributed machine learning effort, LBANN."
        },
        {
            "name": "fbgemm",
            "description": "FBGEMM (Facebook GEneral Matrix Multiplication) is a low-precision,\nhigh-performance matrix-matrix multiplications and convolution library\nfor server-side inference."
        },
        {
            "name": "opensubdiv",
            "description": "OpenSubdiv is a set of open source libraries that implement high\nperformance subdivision surface (subdiv) evaluation on massively\nparallel CPU and GPU architectures. This code path is optimized for\ndrawing deforming surfaces with static topology at interactive\nframerates."
        },
        {
            "name": "lbann",
            "description": "LBANN: Livermore Big Artificial Neural Network Toolkit. A distributed\nmemory, HPC-optimized, model and data parallel training toolkit for deep\nneural networks."
        },
        {
            "name": "py-scikit-learn",
            "description": "A set of python modules for machine learning and data mining."
        },
        {
            "name": "warpx",
            "description": "WarpX is an advanced electromagnetic Particle-In-Cell code. It supports\nmany features including Perfectly-Matched Layers (PML) and mesh\nrefinement. In addition, WarpX is a highly-parallel and highly-optimized\ncode and features hybrid OpenMP/MPI parallelization, advanced\nvectorization techniques and load balancing capabilities. For WarpX'\nPython bindings and PICMI input support, see the 'py-warpx' package."
        },
        {
            "name": "py-pythran",
            "description": "Ahead of Time compiler for numeric kernels."
        },
        {
            "name": "libnetworkit",
            "description": "NetworKit is a growing open-source toolkit for large-scale network\nanalysis. Its aim is to provide tools for the analysis of large networks\nin the size range from thousands to billions of edges. For this purpose,\nit implements efficient graph algorithms, many of them parallel to\nutilize multicore architectures. These are meant to compute standard\nmeasures of network analysis, such as degree sequences, clustering\ncoefficients, and centrality measures. In this respect, NetworKit is\ncomparable to packages such as NetworkX, albeit with a focus on\nparallelism and scalability."
        },
        {
            "name": "xgboost",
            "description": "XGBoost is an optimized distributed gradient boosting library designed\nto be highly efficient, flexible and portable. It implements machine\nlearning algorithms under the Gradient Boosting framework. XGBoost\nprovides a parallel tree boosting (also known as GBDT, GBM) that solve\nmany data science problems in a fast and accurate way. The same code\nruns on major distributed environment (Hadoop, SGE, MPI) and can solve\nproblems beyond billions of examples."
        },
        {
            "name": "blaspp",
            "description": "C++ API for the Basic Linear Algebra Subroutines. Developed by the\nInnovative Computing Laboratory at the University of Tennessee,\nKnoxville."
        },
        {
            "name": "onednn",
            "description": "oneAPI Deep Neural Network Library (oneDNN). Formerly known as Intel\nMKL-DNN and DNNL."
        },
        {
            "name": "py-networkit",
            "description": "NetworKit is a growing open-source toolkit for large-scale network\nanalysis. Its aim is to provide tools for the analysis of large networks\nin the size range from thousands to billions of edges. For this purpose,\nit implements efficient graph algorithms, many of them parallel to\nutilize multicore architectures. These are meant to compute standard\nmeasures of network analysis, such as degree sequences, clustering\ncoefficients, and centrality measures. In this respect, NetworKit is\ncomparable to packages such as NetworkX, albeit with a focus on\nparallelism and scalability."
        },
        {
            "name": "survey",
            "description": "Survey is a high level performance tool product from Trenza, Inc. The\nsurvey collector/analytics framework is a new generation, high level,\nlightweight multiplatform Linux tool set that targets metric collection\nfor high level performance analysis of applications running on both\nsingle node and on large scale platforms, including the Cray platforms.\nThe collector is designed to work on sequential, MPI, OpenMP, and hybrid\ncodes and directly leverages several interfaces available for tools\ninside current MPI implementations including: MPICH, MVAPICH, MPT, and\nOpenMPI. It also supports multiple architectures and has been tested on\nmachines based on Intel, AMD, ARM, and IBM P8/9 processors and\nintegrated GPUs. Survey is a licensed product with the source not openly\navailable. To access the survey source and build with spack please\ncontact: Trenza Inc. via: dmont@trenzasynergy.com or\njeg@trenzasynergy.com"
        },
        {
            "name": "py-torch",
            "description": "Tensors and Dynamic neural networks in Python with strong GPU\nacceleration."
        }
    ]
}