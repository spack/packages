{
    "name": "r-lattice",
    "aliases": [],
    "versions": [
        {
            "name": "0.20-44",
            "sha256": "57b908e3c7ada08a38ad857ee44f44fdf9cfa59d5d9500bda2ccc9c7e96cdb9b"
        },
        {
            "name": "0.20-41",
            "sha256": "54ca557f0cb33df60eb10b883c2ed2847e061ddd57ed9b5dd7695149609d57b5"
        },
        {
            "name": "0.20-38",
            "sha256": "fdeb5e3e50dbbd9d3c5e2fa3eef865132b3eef30fbe53a10c24c7b7dfe5c0a2d"
        },
        {
            "name": "0.20-35",
            "sha256": "0829ab0f4dec55aac6a73bc3411af68441ddb1b5b078d680a7c2643abeaa965d"
        },
        {
            "name": "0.20-34",
            "sha256": "4a1a1cafa9c6660fb9a433b3a51898b8ec8e83abf143c80f99e3e4cf92812518"
        }
    ],
    "build_system": "RPackage",
    "conflicts": [],
    "variants": [],
    "homepage": "http://lattice.r-forge.r-project.org/",
    "maintainers": [
        "glennpj"
    ],
    "patches": [],
    "resources": [],
    "description": "Trellis Graphics for R A powerful and elegant high-level data\nvisualization system inspired by Trellis graphics, with an emphasis on\nmultivariate data. Lattice is sufficient for typical graphics needs, and\nis also flexible enough to handle most nonstandard requirements. See\n?Lattice for an introduction.\n",
    "dependencies": [
        {
            "name": "r",
            "description": "R is 'GNU S', a freely available language and environment for\nstatistical computing and graphics which provides a wide variety of\nstatistical and graphical techniques: linear and nonlinear modelling,\nstatistical tests, time series analysis, classification, clustering,\netc. Please consult the R project homepage for further information."
        }
    ],
    "dependent_to": [
        {
            "name": "r-hexbin",
            "description": "Hexagonal Binning Routines Binning and plotting functions for hexagonal\nbins. Now uses and relies on grid graphics and formal (S4) classes and\nmethods."
        },
        {
            "name": "r-gstat",
            "description": "Spatial and Spatio-Temporal Geostatistical Modelling, Predictionand\nSimulation Variogram modelling; simple, ordinary and universal point or\nblock (co)kriging; spatio-temporal kriging; sequential Gaussian or\nindicator (co)simulation; variogram and variogram map plotting utility\nfunctions; supports sf and stars."
        },
        {
            "name": "r-vsn",
            "description": "Variance stabilization and calibration for microarray data The package\nimplements a method for normalising microarray intensities, and works\nfor single- and multiple-color arrays. It can also be used for data from\nother technologies, as long as they have similar format. The method uses\na robust variant of the maximum-likelihood estimator for an additive-\nmultiplicative error model and affine calibration. The model\nincorporates data calibration step (a.k.a. normalization), a model for\nthe dependence of the variance on the mean intensity and a variance\nstabilizing data transformation. Differences between transformed\nintensities are analogous to \"normalized log-ratios\". However, in\ncontrast to the latter, their variance is independent of the mean, and\nthey are usually more sensitive and specific in detecting differential\ntranscription."
        },
        {
            "name": "r-gbm",
            "description": "Generalized Boosted Regression Models An implementation of extensions to\nFreund and Schapire's AdaBoost algorithm and Friedman's gradient\nboosting machine. Includes regression methods for least squares,\nabsolute loss, t-distribution loss, quantile regression, logistic,\nmultinomial logistic, Poisson, Cox proportional hazards partial\nlikelihood, AdaBoost exponential loss, Huberized hinge loss, and\nLearning to Rank measures (LambdaMart). Originally developed by Greg\nRidgeway."
        },
        {
            "name": "r-sp",
            "description": "Classes and Methods for Spatial Data Classes and methods for spatial\ndata; the classes document where the spatial location information\nresides, for 2D or 3D data. Utility functions are provided, e.g. for\nplotting data as maps, spatial selection, as well as methods for\nretrieving coordinates, for subsetting, print, summary, etc."
        },
        {
            "name": "r-vegan",
            "description": "Community Ecology Package Ordination methods, diversity analysis and\nother functions for community and vegetation ecologists."
        },
        {
            "name": "r-latticeextra",
            "description": "Extra Graphical Utilities Based on Lattice Building on the\ninfrastructure provided by the lattice package, this package provides\nseveral new high-level functions and methods, as well as additional\nutilities such as panel and axis annotation functions."
        },
        {
            "name": "r-affycoretools",
            "description": "Functions useful for those doing repetitive analyses with Affymetrix\nGeneChips Various wrapper functions that have been written to streamline\nthe more common analyses that a core Biostatistician might see."
        },
        {
            "name": "r-mapview",
            "description": "Interactive Viewing of Spatial Data in R Quickly and conveniently create\ninteractive visualisations of spatial data with or without background\nmaps. Attributes of displayed features are fully queryable via pop-up\nwindows. Additional functionality includes methods to visualise true-\nand false-color raster images and bounding boxes."
        },
        {
            "name": "r-adespatial",
            "description": "adespatial: Multivariate Multiscale Spatial Analysis. Tools for the\nmultiscale spatial analysis of multivariate data. Several methods are\nbased on the use of a spatial weighting matrix and its eigenvector\ndecomposition (Moran's Eigenvectors Maps, MEM). Several approaches are\ndescribed in the review Dray et al (2012) <doi:10.1890/11-1183.1>."
        },
        {
            "name": "r-cubist",
            "description": "Rule- And Instance-Based Regression Modeling Regression modeling using\nrules with added instance-based corrections"
        },
        {
            "name": "r-ape",
            "description": "Analyses of Phylogenetics and Evolution Functions for reading, writing,\nplotting, and manipulating phylogenetic trees, analyses of comparative\ndata in a phylogenetic framework, ancestral character analyses, analyses\nof diversification and macroevolution, computing distances from DNA\nsequences, reading and writing nucleotide sequences as well as importing\nfrom BioConductor, and several tools such as Mantel's test, generalized\nskyline plots, graphical exploration of phylogenetic data (alex, trex,\nkronoviz), estimation of absolute evolutionary rates and clock-like\ntrees using mean path lengths and penalized likelihood, dating trees\nwith non-contemporaneous sequences, translating DNA into AA sequences,\nand assessing sequence alignments. Phylogeny estimation can be done with\nthe NJ, BIONJ, ME, MVR, SDM, and triangle methods, and several methods\nhandling incomplete distance matrices (NJ*, BIONJ*, MVR*, and the\ncorresponding triangle method). Some functions call external\napplications (PhyML, Clustal, T-Coffee, Muscle) whose results are\nreturned into R."
        },
        {
            "name": "r-adegraphics",
            "description": "adegraphics: An S4 Lattice-Based Package for the Representation of\nMultivariate Data. Graphical functionalities for the representation of\nmultivariate data. It is a complete re-implementation of the functions\navailable in the 'ade4' package."
        },
        {
            "name": "r-gviz",
            "description": "Plotting data and annotation information along genomic coordinates\nGenomic data analyses requires integrated visualization of known genomic\ninformation and new experimental data. Gviz uses the biomaRt and the\nrtracklayer packages to perform live annotation queries to Ensembl and\nUCSC and translates this to e.g. gene/transcript structures in viewports\nof the grid graphics package. This results in genomic information\nplotted together with your data."
        },
        {
            "name": "r-topgo",
            "description": "Enrichment Analysis for Gene Ontology topGO package provides tools for\ntesting GO terms while accounting for the topology of the GO graph.\nDifferent test statistics and different methods for eliminating local\nsimilarities and dependencies between GO terms can be implemented and\napplied."
        },
        {
            "name": "r-reportingtools",
            "description": "Tools for making reports in various formats The ReportingTools software\npackage enables users to easily display reports of analysis results\ngenerated from sources such as microarray and sequencing data. The\npackage allows users to create HTML pages that may be viewed on a web\nbrowser such as Safari, or in other formats readable by programs such as\nExcel. Users can generate tables with sortable and filterable columns,\nmake and display plots, and link table entries to other data sources\nsuch as NCBI or larger plots within the HTML page. Using the package,\nusers can also produce a table of contents page to link various reports\ntogether for a particular project that can be viewed in a web browser.\nFor more examples, please visit our site: http:// research-\npub.gene.com/ReportingTools."
        },
        {
            "name": "r-mice",
            "description": "Multivariate Imputation by Chained Equations Multiple imputation using\nFully Conditional Specification (FCS) implemented by the MICE algorithm\nas described in Van Buuren and Groothuis-Oudshoorn (2011)\n<doi:10.18637/jss.v045.i03>. Each variable has its own imputation model.\nBuilt-in imputation models are provided for continuous data (predictive\nmean matching, normal), binary data (logistic regression), unordered\ncategorical data (polytomous logistic regression) and ordered\ncategorical data (proportional odds). MICE can also impute continuous\ntwo-level data (normal model, pan, second-level variables). Passive\nimputation can be used to maintain consistency between variables.\nVarious diagnostic plots are available to inspect the quality of the\nimputations."
        },
        {
            "name": "r-mcmcpack",
            "description": "Markov Chain Monte Carlo (MCMC) Package: Contains functions to perform\nBayesian inference using posterior simulation for a number of\nstatistical models. Most simulation is done in compiled C++ written in\nthe Scythe Statistical Library Version 1.0.3. All models return 'coda'\nmcmc objects that can then be summarized using the 'coda' package. Some\nuseful utility functions such as density functions, pseudo-random number\ngenerators for statistical distributions, a general purpose Metropolis\nsampling algorithm, and tools for visualization are provided."
        },
        {
            "name": "r-lumi",
            "description": "BeadArray Specific Methods for Illumina Methylation and Expression\nMicroarrays The lumi package provides an integrated solution for the\nIllumina microarray data analysis. It includes functions of Illumina\nBeadStudio (GenomeStudio) data input, quality control, BeadArray-\nspecific variance stabilization, normalization and gene annotation at\nthe probe level. It also includes the functions of processing Illumina\nmethylation microarrays, especially Illumina Infinium methylation\nmicroarrays."
        },
        {
            "name": "r-effects",
            "description": "Effect Displays for Linear, Generalized Linear, and Other Models\nGraphical and tabular effect displays, e.g., of interactions, for\nvarious statistical models with linear predictors."
        },
        {
            "name": "r-flexmix",
            "description": "Flexible Mixture Modeling A general framework for finite mixtures of\nregression models using the EM algorithm is implemented. The E-step and\nall data handling are provided, while the M-step can be supplied by the\nuser to easily define new models. Existing drivers implement mixtures of\nstandard linear models, generalized linear models and model-based\nclustering."
        },
        {
            "name": "r-caretensemble",
            "description": "caretEnsemble: Ensembles of Caret Models Functions for creating\nensembles of caret models: caretList() and caretStack(). caretList() is\na convenience function for fitting multiple caret::train() models to the\nsame dataset. caretStack() will make linear or non-linear combinations\nof these models, using a caret::train() model as a meta-model, and\ncaretEnsemble() will make a robust linear combination of models using a\nGLM."
        },
        {
            "name": "r-fit-models",
            "description": "Compare Fitted Models The fit.models function and its associated methods\n(coefficients, print, summary, plot, etc.) were originally provided in\nthe robust package to compare robustly and classically fitted model\nobjects. See chapters 2, 3, and 5 in Insightful (2002) 'Robust Library\nUser's Guide' <http://robust.r-forge.r-project.org/Robust.pdf>). The aim\nof the fit.models package is to separate this fitted model object\ncomparison functionality from the robust package and to extend it to\nsupport fitting methods (e.g., classical, robust, Bayesian, regularized,\netc.) more generally."
        },
        {
            "name": "r-psych",
            "description": "Procedures for Psychological, Psychometric, and Personality Research A\ngeneral purpose toolbox for personality, psychometric theory and\nexperimental psychology. Functions are primarily for multivariate\nanalysis and scale construction using factor analysis, principal\ncomponent analysis, cluster analysis and reliability analysis, although\nothers provide basic descriptive statistics. Item Response Theory is\ndone using factor analysis of tetrachoric and polychoric correlations.\nFunctions for analyzing data at multiple levels include within and\nbetween group statistics, including correlations and factor analysis.\nFunctions for simulating and testing particular item and test structures\nare included. Several functions serve as a useful front end for\nstructural equation modeling. Graphical displays of path diagrams,\nfactor analysis and structural equation models are created using basic\ngraphics. Some of the functions are written to support a book on\npsychometric theory as well as publications in personality research. For\nmore information, see the <http://personality-project.org/r> web page."
        },
        {
            "name": "r-robust",
            "description": "Port of the S+ Robust Library Methods for robust statistics, a state of\nthe art in the early 2000s, notably for robust regression and robust\nmultivariate analysis."
        },
        {
            "name": "r-hmisc",
            "description": "Harrell Miscellaneous Contains many functions useful for data analysis,\nhigh-level graphics, utility operations, functions for computing sample\nsize and power, importing and annotating datasets, imputing missing\nvalues, advanced table making, variable clustering, character string\nmanipulation, conversion of R objects to LaTeX and html code, and\nrecoding variables."
        },
        {
            "name": "r-flexclust",
            "description": "The main function kcca implements a general framework for k-centroids\ncluster analysis supporting arbitrary distance measures and centroid\ncomputation. Further cluster methods include hard competitive learning,\nneural gas, and QT clustering. There are numerous visualization methods\nfor cluster results (neighborhood graphs, convex cluster hulls,\nbarcharts of centroids, ...), and bootstrap methods for the analysis of\ncluster stability."
        },
        {
            "name": "r-copula",
            "description": "Multivariate Dependence with Copulas Classes (S4) of commonly used\nelliptical, Archimedean, extreme-value and other copula families, as\nwell as their rotations, mixtures and asymmetrizations. Nested\nArchimedean copulas, related tools and special functions. Methods for\ndensity, distribution, random number generation, bivariate dependence\nmeasures, Rosenblatt transform, Kendall distribution function,\nperspective and contour plots. Fitting of copula models with potentially\npartly fixed parameters, including standard errors. Serial independence\ntests, copula specification tests (independence, exchangeability, radial\nsymmetry, extreme-value dependence, goodness-of-fit) and model selection\nbased on cross-validation. Empirical copula, smoothed versions, and non-\nparametric estimators of the Pickands dependence function."
        },
        {
            "name": "r-lme4",
            "description": "Linear Mixed-Effects Models using 'Eigen' and S4 Fit linear and\ngeneralized linear mixed-effects models. The models and their components\nare represented using S4 classes and methods. The core computational\nalgorithms are implemented using the 'Eigen' C++ library for numerical\nlinear algebra and 'RcppEigen' \"glue\"."
        },
        {
            "name": "r-locfit",
            "description": "Local regression, likelihood and density estimation Local regression,\nlikelihood and density estimation methods as described in the 1999 book\nby Loader."
        },
        {
            "name": "r-runjags",
            "description": "Interface Utilities, Model Templates, Parallel Computing Methods and\nAdditional Distributions for MCMC Models in JAGS: User-friendly\ninterface utilities for MCMC models via Just Another Gibbs Sampler\n(JAGS), facilitating the use of parallel (or distributed) processors for\nmultiple chains, automated control of convergence and sample length\ndiagnostics, and evaluation of the performance of a model using drop-k\nvalidation or against simulated data. Template model specifications can\nbe generated using a standard lme4-style formula interface to assist\nusers less familiar with the BUGS syntax. A JAGS extension module\nprovides additional distributions including the Pareto family of\ndistributions, the DuMouchel prior and the half-Cauchy prior."
        },
        {
            "name": "r-spacetime",
            "description": "Classes and Methods for Spatio-Temporal Data Classes and methods for\nspatio-temporal data, including space-time regular lattices, sparse\nlattices, irregular data, and trajectories; utility functions for\nplotting data as map sequences (lattice or animation) or multiple time\nseries; methods for spatial and temporal selection and subsetting, as\nwell as for spatial/temporal/spatio-temporal matching or aggregation,\nretrieving coordinates, print, summary, etc."
        },
        {
            "name": "r-nlme",
            "description": "Fit and compare Gaussian linear and nonlinear mixed-effects models Fit\nand compare Gaussian linear and nonlinear mixed-effects models."
        },
        {
            "name": "r-coda",
            "description": "Output Analysis and Diagnostics for MCMC Provides functions for\nsummarizing and plotting the output from Markov Chain Monte Carlo (MCMC)\nsimulations, as well as diagnostic tests of convergence to the\nequilibrium distribution of the Markov chain."
        },
        {
            "name": "r-factominer",
            "description": "Multivariate Exploratory Data Analysis and Data Mining Exploratory data\nanalysis methods to summarize, visualize and describe datasets. The main\nprincipal component methods are available, those with the largest\npotential in terms of applications: principal component analysis (PCA)\nwhen variables are quantitative, correspondence analysis (CA) and\nmultiple correspondence analysis (MCA) when variables are categorical,\nMultiple Factor Analysis when variables are structured in groups, etc.\nand hierarchical cluster analysis. F. Husson, S. Le and J. Pages (2017)."
        },
        {
            "name": "r-geneplotter",
            "description": "Graphics related functions for Bioconductor Functions for plotting\ngenomic data."
        },
        {
            "name": "r-hh",
            "description": "Statistical Analysis and Data Display: Heiberger and Holland. Support\nsoftware for Statistical Analysis and Data Display (Second Edition,\nSpringer, ISBN 978-1-4939-2121-8, 2015) and (First Edition, Springer,\nISBN 0-387-40270-5, 2004) by Richard M. Heiberger and Burt Holland. This\ncontemporary presentation of statistical methods features extensive use\nof graphical displays for exploring data and for displaying the\nanalysis. The second edition includes redesigned graphics and additional\nchapters. The authors emphasize how to construct and interpret graphs,\ndiscuss principles of graphical design, and show how accompanying\ntraditional tabular results are used to confirm the visual impressions\nderived directly from the graphs. Many of the graphical formats are\nnovel and appear here for the first time in print. All chapters have\nexercises. All functions introduced in the book are in the package. R\ncode for all examples, both graphs and tables, in the book is included\nin the scripts directory of the package."
        },
        {
            "name": "r-rrcov",
            "description": "Scalable Robust Estimators with High Breakdown Point Robust Location and\nScatter Estimation and Robust Multivariate Analysis with High Breakdown\nPoint: principal component analysis (Filzmoser and Todorov (2013),\n<doi:10.1016/j.ins.2012.10.017>), linear and quadratic discriminant\nanalysis (Todorov and Pires (2007)), multivariate tests (Todorov and\nFilzmoser (2010) <doi:10.1016/j.csda.2009.08.015>), outlier detection\n(Todorov et al. (2010) <doi:10.1007/s11634-010-0075-2>). See also\nTodorov and Filzmoser (2009) <ISBN-13:978-3838108148>, Todorov and\nFilzmoser (2010) <doi:10.18637/jss.v032.i03> and Boudt et al. (2019)\n<doi:10.1007/s11222-019-09869-x>."
        },
        {
            "name": "r-maptools",
            "description": "Tools for Handling Spatial Objects Set of tools for manipulating and\nreading geographic data, in particular ESRI shapefiles; C code used from\nshapelib. It includes binary access to GSHHG shoreline files. The\npackage also provides interface wrappers for exchanging spatial objects\nwith packages such as PBSmapping, spatstat, maps, RArcInfo, Stata tmap,\nWinBUGS, Mondrian, and others."
        },
        {
            "name": "r-allelicimbalance",
            "description": "Investigates Allele Specific Expression Provides a framework for allelic\nspecific expression investigation using RNA-seq data."
        },
        {
            "name": "r-shortread",
            "description": "FASTQ input and manipulation This package implements sampling,\niteration, and input of FASTQ files. The package includes functions for\nfiltering and trimming reads, and for generating a quality assessment\nreport. Data are represented as DNAStringSet-derived objects, and easily\nmanipulated for a diversity of purposes. The package also contains\nlegacy support for early single-end, ungapped alignment formats."
        },
        {
            "name": "r-rminer",
            "description": "Data Mining Classification and Regression Methods Facilitates the use of\ndata mining algorithms in classification and regression (including time\nseries forecasting) tasks by presenting a short and coherent set of\nfunctions. Versions: 1.4.6 / 1.4.5 / 1.4.4 new automated machine\nlearning (AutoML) and ensembles, via improved fit(), mining() and\nmparheuristic() functions, and new categorical preprocessing, via\nimproved delevels() function; 1.4.3 new metrics (e.g., macro precision,\nexplained variance), new \"lssvm\" model and improved mparheuristic()\nfunction; 1.4.2 new \"NMAE\" metric, \"xgboost\" and \"cv.glmnet\" models (16\nclassification and 18 regression models); 1.4.1 new tutorial and more\nrobust version; 1.4 - new classification and regression models, with a\ntotal of 14 classification and 15 regression methods, including:\nDecision Trees, Neural Networks, Support Vector Machines, Random\nForests, Bagging and Boosting; 1.3 and 1.3.1 - new classification and\nregression metrics; 1.2 - new input importance methods via improved\nImportance() function; 1.0 - first version."
        },
        {
            "name": "r-survey",
            "description": "Analysis of Complex Survey Samples Summary statistics, two-sample tests,\nrank tests, generalised linear models, cumulative link models, Cox\nmodels, loglinear models, and general maximum pseudolikelihood\nestimation for multistage stratified, cluster-sampled, unequally\nweighted survey samples. Variances by Taylor series linearisation or\nreplicate weights. Post-stratification, calibration, and raking. Two-\nphase subsampling designs. Graphics. PPS sampling without replacement.\nPrincipal components, factor analysis."
        },
        {
            "name": "r-metap",
            "description": "Meta-Analysis of Significance Values The canonical way to perform meta-\nanalysis involves using effect sizes. When they are not available this\npackage provides a number of methods for meta-analysis of significance\nvalues including the methods of Edgington, Fisher, Lancaster, Stouffer,\nTippett, and Wilkinson; a number of data-sets to replicate published\nresults; and a routine for graphical display."
        },
        {
            "name": "r-caret",
            "description": "Classification and Regression Training Misc functions for training and\nplotting classification and regression models."
        },
        {
            "name": "r-chipseq",
            "description": "A package for analyzing chipseq data Tools for helping process short\nread data for chipseq experiments"
        },
        {
            "name": "r-affyqcreport",
            "description": "QC Report Generation for affyBatch objects This package creates a QC\nreport for an AffyBatch object. The report is intended to allow the user\nto quickly assess the quality of a set of arrays in an AffyBatch object."
        },
        {
            "name": "r-deseq",
            "description": "Differential gene expression analysis based on the negative binomial\ndistribution Estimate variance-mean dependence in count data from high-\nthroughput sequencing assays and test for differential expression based\non a model using the negative binomial distribution"
        },
        {
            "name": "r-msnbase",
            "description": "Base Functions and Classes for Mass Spectrometry and Proteomics MSnbase\nprovides infrastructure for manipulation, processing and visualisation\nof mass spectrometry and proteomics data, ranging from raw to\nquantitative and annotated data."
        },
        {
            "name": "r-zoo",
            "description": "S3 Infrastructure for Regular and Irregular Time Series (Z's Ordered\nObservations) An S3 class with methods for totally ordered indexed\nobservations. It is particularly aimed at irregular time series of\nnumeric vectors/matrices and factors. zoo's key design goals are\nindependence of a particular index/date/time class and consistency with\nts and base R by providing methods to extend standard generics."
        },
        {
            "name": "r-minfi",
            "description": "Analyze Illumina Infinium DNA methylation arrays Tools to analyze &\nvisualize Illumina Infinium methylation arrays."
        },
        {
            "name": "r-methylumi",
            "description": "Handle Illumina methylation data This package provides classes for\nholding and manipulating Illumina methylation data. Based on eSet, it\ncan contain MIAME information, sample information, feature information,\nand multiple matrices of data. An \"intelligent\" import function,\nmethylumiR can read the Illumina text files and create a MethyLumiSet.\nmethylumIDAT can directly read raw IDAT files from HumanMethylation27\nand HumanMethylation450 microarrays. Normalization, background\ncorrection, and quality control features for GoldenGate, Infinium, and\nInfinium HD arrays are also included."
        },
        {
            "name": "r-matrix",
            "description": "Sparse and Dense Matrix Classes and Methods A rich hierarchy of matrix\nclasses, including triangular, symmetric, and diagonal matrices, both\ndense and sparse and with pattern, logical and numeric entries. Numerous\nmethods for and operations on these matrices, using 'LAPACK' and\n'SuiteSparse' libraries."
        },
        {
            "name": "r-rms",
            "description": "Regression Modeling Strategies Regression modeling, testing, estimation,\nvalidation, graphics, prediction, and typesetting by storing enhanced\nmodel design attributes in the fit. 'rms' is a collection of functions\nthat assist with and streamline modeling. It also contains functions for\nbinary and ordinal logistic regression models, ordinal models for\ncontinuous Y with a variety of distribution families, and the Buckley-\nJames multiple regression model for right-censored responses, and\nimplements penalized maximum likelihood estimation for logistic and\nordinary linear models. 'rms' works with almost any regression model,\nbut it was especially written to work with binary or ordinal regression\nmodels, Cox regression, accelerated failure time models, ordinary linear\nmodels, the Buckley-James model, generalized least squares for serially\nor spatially correlated observations, generalized linear models, and\nquantile regression."
        }
    ]
}