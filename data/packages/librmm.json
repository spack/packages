{
    "name": "librmm",
    "aliases": [],
    "versions": [
        {
            "name": "0.15.0",
            "sha256": "599f97b95d169a90d11296814763f7e151a8a1e060ba10bc6c8f4684a5cd7972"
        }
    ],
    "build_system": "CMakePackage",
    "conflicts": [
        {
            "name": "+ipo",
            "spec": "^cmake@:3.8",
            "description": "+ipo is not supported by CMake < 3.9"
        }
    ],
    "variants": [
        {
            "name": "build_type",
            "default": "RelWithDebInfo",
            "description": "CMake build type"
        },
        {
            "name": "ipo",
            "default": false,
            "description": "CMake interprocedural optimization"
        }
    ],
    "homepage": "https://github.com/rapidsai/rmm",
    "maintainers": [],
    "patches": [],
    "resources": [],
    "description": "RMM: RAPIDS Memory Manager. Achieving optimal performance in GPU-centric\nworkflows frequently requires customizing how host and device memory are\nallocated.\n",
    "dependencies": [
        {
            "name": "cmake",
            "description": "A cross-platform, open-source build system. CMake is a family of tools\ndesigned to build, test and package software."
        },
        {
            "name": "cuda",
            "description": "CUDA is a parallel computing platform and programming model invented by\nNVIDIA. It enables dramatic increases in computing performance by\nharnessing the power of the graphics processing unit (GPU). Note: This\npackage does not currently install the drivers necessary to run CUDA.\nThese will need to be installed manually. See:\nhttps://docs.nvidia.com/cuda/ for details."
        }
    ],
    "dependent_to": [
        {
            "name": "libcudf",
            "description": "Built based on the Apache Arrow columnar memory format, cuDF is a GPU\nDataFrame library for loading, joining, aggregating, filtering, and\notherwise manipulating data."
        },
        {
            "name": "py-rmm",
            "description": "RMM: RAPIDS Memory Manager. Achieving optimal performance in GPU-centric\nworkflows frequently requires customizing how host and device memory are\nallocated."
        }
    ]
}