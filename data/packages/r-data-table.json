{
    "name": "r-data-table",
    "aliases": [],
    "versions": [
        {
            "name": "1.14.2",
            "sha256": "f741b951e5937440139514aedbae78dbd6862d825066848bdb006aa02c2f3d2b"
        },
        {
            "name": "1.13.6",
            "sha256": "d50cdd4c4f89cabf83baa9114e49a3b8179f403c499d6e0be7791a44ffcd3e9b"
        },
        {
            "name": "1.12.8",
            "sha256": "d3a75f3a355ff144cc20a476041617e21fcf2a9f79265fd9bbd4693f3671f9dc"
        },
        {
            "name": "1.12.2",
            "sha256": "db55c18f0d703a8bc1c806dd1f7551bb405cb867717f52ef9dd64405394d22f5"
        },
        {
            "name": "1.12.0",
            "sha256": "611b112123dbd4ebd5200770fcdfaaeaab622adeb2b290d36018d3092742e3f7"
        },
        {
            "name": "1.11.8",
            "sha256": "dc427465599cadd848b28a78e2fce3362867847b44148252054385999fe566d9"
        },
        {
            "name": "1.11.6",
            "sha256": "ac6783c18e94d1bc05702ddec9fd87c542c744f640132f5ffc373348be84d9e9"
        },
        {
            "name": "1.11.4",
            "sha256": "fdccf1dec3f38bb344163163decf3ffa0c0f8e2c70daa1bec8aac422716e81d5"
        },
        {
            "name": "1.11.2",
            "sha256": "44f548517426c0444f7ce993bf93350be9f31e214d3dad39f9a680a53f9e6e64"
        },
        {
            "name": "1.11.0",
            "sha256": "ae81e07a39ef0cb65751c8987df21246d57ebc5e4ef7e9c511225a9d58193758"
        },
        {
            "name": "1.10.4-3",
            "sha256": "ba8b4f1b96b16e7f9765fc49c5028f21ef2210fc46cf962f4f7ea7901f9d8a89"
        },
        {
            "name": "1.10.4-2",
            "sha256": "27d703e0746b25cab0229285013e955f676ab9d8460d7f7c3c01df4c257b2d95"
        },
        {
            "name": "1.10.4-1",
            "sha256": "1ea6f9d45c94974f69b6918a248853ba24cbd80cdd1309b1be43eca65d6e7a75"
        },
        {
            "name": "1.10.4",
            "sha256": "865fdf6aad389071ad063ec1c75a78ffc86eeb88bba011f3ea5281d243966b7a"
        },
        {
            "name": "1.10.2",
            "sha256": "95a3ae6b273910571e25400a5cab1f7542cf589272c012c268f4b4724216f658"
        },
        {
            "name": "1.10.0",
            "sha256": "cf61732ef9b38ecb6579055d1cd145198ad23a5a9ae4378f94a1494e6c56c884"
        },
        {
            "name": "1.9.8",
            "sha256": "dadb21a14a7f4d60955cdd8fb9779136833498be97b1625914e9a6b580646f4d"
        },
        {
            "name": "1.9.6",
            "sha256": "6f74c349c1731823aef6899edcf18418454167d04eba983e3a6fe17ee9fd236e"
        }
    ],
    "latest_version": "1.14.2",
    "build_system": "RPackage",
    "conflicts": [],
    "variants": [],
    "homepage": "https://cloud.r-project.org/package=data.table",
    "maintainers": [
        "glennpj"
    ],
    "patches": [],
    "resources": [],
    "description": "Extension of `data.frame`. Fast aggregation of large data (e.g. 100GB in\nRAM), fast ordered joins, fast add/modify/delete of columns by group\nusing no copies at all, list columns and a fast file reader (fread).\nOffers a natural and flexible syntax, for faster development.\n",
    "dependencies": [
        {
            "name": "r",
            "description": "R is 'GNU S', a freely available language and environment for\nstatistical computing and graphics which provides a wide variety of\nstatistical and graphical techniques: linear and nonlinear modelling,\nstatistical tests, time series analysis, classification, clustering,\netc. Please consult the R project homepage for further information."
        },
        {
            "name": "zlib",
            "description": "A free, general-purpose, legally unencumbered lossless data-compression\nlibrary."
        }
    ],
    "dependent_to": [
        {
            "name": "r-biomartr",
            "description": "Genomic Data Retrieval. Perform large scale genomic data retrieval and\nfunctional annotation retrieval. This package aims to provide users with\na standardized way to automate genome, proteome, 'RNA', coding sequence\n('CDS'), 'GFF', and metagenome retrieval from 'NCBI RefSeq', 'NCBI\nGenbank', 'ENSEMBL', 'ENSEMBLGENOMES', and 'UniProt' databases.\nFurthermore, an interface to the 'BioMart' database (Smedley et al.\n(2009) <doi:10.1186/1471-2164-10-22>) allows users to retrieve\nfunctional annotation for genomic loci. In addition, users can download\nentire databases such as 'NCBI RefSeq' (Pruitt et al. (2007)\n<doi:10.1093/nar/gkl842>), 'NCBI nr', 'NCBI nt', 'NCBI Genbank' (Benson\net al. (2013) <doi:10.1093/nar/gks1195>), etc. as well as 'ENSEMBL' and\n'ENSEMBLGENOMES' with only one command."
        },
        {
            "name": "r-quickplot",
            "description": "A System of Plotting Optimized for Speed and Modularity. A high-level\nplotting system, built using 'grid' graphics, that is optimized for\nspeed and modularity. This has great utility for quick visualizations\nwhen testing code, with the key benefit that visualizations are updated\nindependently of one another."
        },
        {
            "name": "r-isdparser",
            "description": "Parse 'NOAA' Integrated Surface Data Files. Tools for parsing 'NOAA'\nIntegrated Surface Data ('ISD') files, described at\n<https://www.ncdc.noaa.gov/isd>. Data includes for example, wind speed\nand direction, temperature, cloud data, sea level pressure, and more.\nIncludes data from approximately 35,000 stations worldwide, though best\ncoverage is in North America/Europe/Australia. Data is stored as\nvariable length ASCII character strings, with most fields optional.\nIncluded are tools for parsing entire files, or individual lines of\ndata."
        },
        {
            "name": "r-rnoaa",
            "description": "'NOAA' Weather Data from R. Client for many 'NOAA' data sources\nincluding the 'NCDC' climate 'API' at <https://www.ncdc.noaa.gov/cdo-\nweb/webservices/v2>, with functions for each of the 'API' 'endpoints':\ndata, data categories, data sets, data types, locations, location\ncategories, and stations. In addition, we have an interface for 'NOAA'\nsea ice data, the 'NOAA' severe weather inventory, 'NOAA' Historical\nObserving 'Metadata' Repository ('HOMR') data, 'NOAA' storm data via\n'IBTrACS', tornado data via the 'NOAA' storm prediction center, and\nmore."
        },
        {
            "name": "r-geoquery",
            "description": "Get data from NCBI Gene Expression Omnibus (GEO). The NCBI Gene\nExpression Omnibus (GEO) is a public repository of microarray data.\nGiven the rich and varied nature of this resource, it is only natural to\nwant to apply BioConductor tools to these data. GEOquery is the bridge\nbetween GEO and BioConductor."
        },
        {
            "name": "r-gsodr",
            "description": "A Global Surface Summary of the Day (GSOD) Weather Data Client for R.\nProvides automated downloading, parsing, cleaning, unit conversion and\nformatting of Global Surface Summary of the Day ('GSOD') weather data\nfrom the from the USA National Centers for Environmental Information\n('NCEI'). Units are converted from from United States Customary System\n('USCS') units to International System of Units ('SI'). Stations may be\nindividually checked for number of missing days defined by the user,\nwhere stations with too many missing observations are omitted. Only\nstations with valid reported latitude and longitude values are permitted\nin the final data. Additional useful elements, saturation vapour\npressure ('es'), actual vapour pressure ('ea') and relative humidity\n('RH') are calculated from the original data using the improved August-\nRoche-Magnus approximation (Alduchov & Eskridge 1996) and included in\nthe final data set. The resulting metadata include station\nidentification information, country, state, latitude, longitude,\nelevation, weather observations and associated flags. For information on\nthe 'GSOD' data from 'NCEI', please see the 'GSOD' 'readme.txt' file\navailable from, <https://www1.ncdc.noaa.gov/pub/data/gsod/readme.txt>."
        },
        {
            "name": "r-rio",
            "description": "A Swiss-Army Knife for Data I/O. Streamlined data import and export by\nmaking assumptions that the user is probably willing to make: 'import()'\nand 'export()' determine the data structure from the file extension,\nreasonable defaults are used for data import and export (e.g.,\n'stringsAsFactors=FALSE'), web-based import is natively supported\n(including from SSL/HTTPS), compressed files can be read directly\nwithout explicit decompression, and fast import packages are used where\nappropriate. An additional convenience function, 'convert()', provides a\nsimple method for converting between file types."
        },
        {
            "name": "r-scater",
            "description": "Single-Cell Analysis Toolkit for Gene Expression Data in R. A collection\nof tools for doing various analyses of single-cell RNA-seq gene\nexpression data, with a focus on quality control and visualization."
        },
        {
            "name": "r-fgsea",
            "description": "Fast Gene Set Enrichment Analysis. The package implements an algorithm\nfor fast gene set enrichment analysis. Using the fast algorithm allows\nto make more permutations and get more fine grained p-values, which\nallows to use accurate stantard approaches to multiple hypothesis\ncorrection."
        },
        {
            "name": "r-modelmetrics",
            "description": "Rapid Calculation of Model Metrics. Collection of metrics for evaluating\nmodels written in C++ using 'Rcpp'. Popular metrics include area under\nthe curve, log loss, root mean square error, etc."
        },
        {
            "name": "r-mlr",
            "description": "Machine Learning in R. Interface to a large number of classification and\nregression techniques, including machine-readable parameter\ndescriptions. There is also an experimental extension for survival\nanalysis, clustering and general, example-specific cost-sensitive\nlearning. Generic resampling, including cross-validation, bootstrapping\nand subsampling. Hyperparameter tuning with modern optimization\ntechniques, for single- and multi-objective problems. Filter and wrapper\nmethods for feature selection. Extension of basic learners with\nadditional operations common in machine learning, also allowing for easy\nnested resampling. Most operations can be parallelized."
        },
        {
            "name": "r-minfi",
            "description": "Analyze Illumina Infinium DNA methylation arrays. Tools to analyze &\nvisualize Illumina Infinium methylation arrays."
        },
        {
            "name": "r-plotly",
            "description": "Create Interactive Web Graphics via 'plotly.js'. Create interactive web\ngraphics from 'ggplot2' graphs and/or a custom interface to the (MIT-\nlicensed) JavaScript library 'plotly.js' inspired by the grammar of\ngraphics."
        },
        {
            "name": "r-dtplyr",
            "description": "Data Table Back-End for 'dplyr'. Provides a data.table backend for\n'dplyr'. The goal of 'dtplyr' is to allow you to write 'dplyr' code that\nis automatically translated to the equivalent, but usually much faster,\ndata.table code."
        },
        {
            "name": "r-spades-tools",
            "description": "Tools for Spatially Explicit Discrete Event Simulation (SpaDES) Models.\nProvides GIS and map utilities, plus additional modeling tools for\ndeveloping cellular automata, dynamic raster models, and agent based\nmodels in 'SpaDES'. Included are various methods for spatial spreading,\nspatial agents, GIS operations, random map generation, and others. See\n'?SpaDES.tools' for an categorized overview of these additional tools."
        },
        {
            "name": "r-bsseq",
            "description": "Analyze, manage and store bisulfite sequencing data. A collection of\ntools for analyzing and visualizing bisulfite sequencing data."
        },
        {
            "name": "r-require",
            "description": "Installing and Loading R Packages for Reproducible Workflows. A single\nkey function, 'Require' that wraps 'install.packages',\n'remotes::install_github', 'versions::install.versions', and\n'base::require' that allows for reproducible workflows. As with other\nfunctions in a reproducible workflow, this package emphasizes functions\nthat return the same result whether it is the first or subsequent times\nrunning the function. Maturing."
        },
        {
            "name": "r-reproducible",
            "description": "A Set of Tools that Enhance Reproducibility Beyond Package Management.\nCollection of high-level, machine- and OS-independent tools for making\ndeeply reproducible and reusable content in R. The two workhorse\nfunctions are Cache and prepInputs; these allow for: nested caching,\nrobust to environments, and objects with environments (like functions);\nand data retrieval and processing in continuous workflow environments.\nIn all cases, efforts are made to make the first and subsequent calls of\nfunctions have the same result, but vastly faster at subsequent times by\nway of checksums and digesting. Several features are still under active\ndevelopment, including cloud storage of cached objects, allowing for\nsharing between users. Several advanced options are available, see\n?reproducibleOptions."
        },
        {
            "name": "r-abaenrichment",
            "description": "Gene expression enrichment in human brain regions. The package\nABAEnrichment is designed to test for enrichment of user defined\ncandidate genes in the set of expressed genes in different human brain\nregions. The core function 'aba_enrich' integrates the expression of the\ncandidate gene set (averaged across donors) and the structural\ninformation of the brain using an ontology, both provided by the Allen\nBrain Atlas project. 'aba_enrich' interfaces the ontology enrichment\nsoftware FUNC to perform the statistical analyses. Additional functions\nprovided in this package like 'get_expression' and 'plot_expression'\nfacilitate exploring the expression data, and besides the standard\ncandidate vs. background gene set enrichment, also three additional\ntests are implemented, e.g. for cases when genes are ranked instead of\ndivided into candidate and background."
        },
        {
            "name": "r-splitstackshape",
            "description": "Stack and Reshape Datasets After Splitting Concatenated Values. Online\ndata collection tools like Google Forms often export multiple-response\nquestions with data concatenated in cells. The concat.split (cSplit)\nfamily of functions splits such data into separate cells. The package\nalso includes functions to stack groups of columns and to reshape wide\ndata, even when the data are \"unbalanced\" something which reshape (from\nbase R) does not handle, and which melt and dcast from reshape2 do not\neasily handle."
        },
        {
            "name": "r-mlrmbo",
            "description": "Bayesian Optimization and Model-Based Optimization of Expensive Black-\nBox Functions. Flexible and comprehensive R toolbox for model-based\noptimization ('MBO'), also known as Bayesian optimization. It is\ndesigned for both single- and multi-objective optimization with mixed\ncontinuous, categorical and conditional parameters. The machine learning\ntoolbox 'mlr' provide dozens of regression learners to model the\nperformance of the target algorithm with respect to the parameter\nsettings. It provides many different infill criteria to guide the search\nprocess. Additional features include multi-point batch proposal,\nparallel execution as well as visualization and sophisticated logging\nmechanisms, which is especially useful for teaching and understanding of\nalgorithm behavior. 'mlrMBO' is implemented in a modular fashion, such\nthat single components can be easily replaced or adapted by the user for\nspecific use cases."
        },
        {
            "name": "r-caretensemble",
            "description": "Ensembles of Caret Models. Functions for creating ensembles of caret\nmodels: caretList() and caretStack(). caretList() is a convenience\nfunction for fitting multiple caret::train() models to the same dataset.\ncaretStack() will make linear or non-linear combinations of these\nmodels, using a caret::train() model as a meta-model, and\ncaretEnsemble() will make a robust linear combination of models using a\nGLM."
        },
        {
            "name": "r-xgboost",
            "description": "Extreme Gradient Boosting. Extreme Gradient Boosting, which is an\nefficient implementation of gradient boosting framework. This package is\nits R interface. The package includes efficient linear model solver and\ntree learning algorithms. The package can automatically do parallel\ncomputation on a single machine which could be more than 10 times faster\nthan existing gradient boosting packages. It supports various objective\nfunctions, including regression, classification and ranking. The package\nis made to be extensible, so that users are also allowed to define their\nown objectives easily."
        },
        {
            "name": "r-spades-core",
            "description": "Utilities for Developing and Running Spatially Explicit Discrete Event\nModels. Provides the core framework for a discrete event system (DES) to\nimplement acomplete data-to-decisions, reproducible workflow. The core\nDES components facilitate modularity, and easily enable the user to\ninclude additional functionality by running user-built modules. Includes\nconditional scheduling, restart after interruption, packaging of\nreusable modules, tools for developing arbitrary automated workflows,\nautomated interweaving of modules of different temporal resolution, and\ntools for visualizing and understanding the DES project."
        },
        {
            "name": "r-phyloseq",
            "description": "Handling and analysis of high-throughput microbiome census data.\nphyloseq provides a set of classes and tools to facilitate the import,\nstorage, analysis, and graphical display of microbiome census data."
        },
        {
            "name": "r-hmisc",
            "description": "Harrell Miscellaneous. Contains many functions useful for data analysis,\nhigh-level graphics, utility operations, functions for computing sample\nsize and power, importing and annotating datasets, imputing missing\nvalues, advanced table making, variable clustering, character string\nmanipulation, conversion of R objects to LaTeX and html code, and\nrecoding variables."
        }
    ]
}