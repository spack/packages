{
    "name": "r-nnet",
    "aliases": [],
    "versions": [
        {
            "name": "7.3-14",
            "sha256": "5d1b9e9764d74d16c651f18f949aa4e9e2995ba64633cbfa2c6a7355ae30f4af"
        },
        {
            "name": "7.3-12",
            "sha256": "2723523e8581cc0e2215435ac773033577a16087a3f41d111757dd96b8c5559d"
        }
    ],
    "build_system": "RPackage",
    "conflicts": [],
    "variants": [],
    "homepage": "http://www.stats.ox.ac.uk/pub/MASS4/",
    "maintainers": [
        "glennpj"
    ],
    "patches": [],
    "resources": [],
    "description": "Feed-Forward Neural Networks and Multinomial Log-Linear Models Software\nfor feed-forward neural networks with a single hidden layer, and for\nmultinomial log-linear models.\n",
    "dependencies": [
        {
            "name": "r",
            "description": "R is 'GNU S', a freely available language and environment for\nstatistical computing and graphics which provides a wide variety of\nstatistical and graphical techniques: linear and nonlinear modelling,\nstatistical tests, time series analysis, classification, clustering,\netc. Please consult the R project homepage for further information."
        }
    ],
    "dependent_to": [
        {
            "name": "r-rminer",
            "description": "Data Mining Classification and Regression Methods Facilitates the use of\ndata mining algorithms in classification and regression (including time\nseries forecasting) tasks by presenting a short and coherent set of\nfunctions. Versions: 1.4.6 / 1.4.5 / 1.4.4 new automated machine\nlearning (AutoML) and ensembles, via improved fit(), mining() and\nmparheuristic() functions, and new categorical preprocessing, via\nimproved delevels() function; 1.4.3 new metrics (e.g., macro precision,\nexplained variance), new \"lssvm\" model and improved mparheuristic()\nfunction; 1.4.2 new \"NMAE\" metric, \"xgboost\" and \"cv.glmnet\" models (16\nclassification and 18 regression models); 1.4.1 new tutorial and more\nrobust version; 1.4 - new classification and regression models, with a\ntotal of 14 classification and 15 regression methods, including:\nDecision Trees, Neural Networks, Support Vector Machines, Random\nForests, Bagging and Boosting; 1.3 and 1.3.1 - new classification and\nregression metrics; 1.2 - new input importance methods via improved\nImportance() function; 1.0 - first version."
        },
        {
            "name": "r-corhmm",
            "description": "Hidden Markov Models of Character Evolution Fits hidden Markov models of\ndiscrete character evolution which allow different transition rate\nclasses on different portions of a phylogeny. Beaulieu et al (2013)\n<doi:10.1093/sysbio/syt034>."
        },
        {
            "name": "r-chemometrics",
            "description": "R companion to the book \"Introduction to Multivariate Statistical\nAnalysis in Chemometrics\" written by K. Varmuza and P. Filzmoser (2009)."
        },
        {
            "name": "r-forecast",
            "description": "Forecasting Functions for Time Series and Linear Models Methods and\ntools for displaying and analysing univariate time series forecasts\nincluding exponential smoothing via state space models and automatic\nARIMA modelling."
        },
        {
            "name": "r-mice",
            "description": "Multivariate Imputation by Chained Equations Multiple imputation using\nFully Conditional Specification (FCS) implemented by the MICE algorithm\nas described in Van Buuren and Groothuis-Oudshoorn (2011)\n<doi:10.18637/jss.v045.i03>. Each variable has its own imputation model.\nBuilt-in imputation models are provided for continuous data (predictive\nmean matching, normal), binary data (logistic regression), unordered\ncategorical data (polytomous logistic regression) and ordered\ncategorical data (proportional odds). MICE can also impute continuous\ntwo-level data (normal model, pan, second-level variables). Passive\nimputation can be used to maintain consistency between variables.\nVarious diagnostic plots are available to inspect the quality of the\nimputations."
        },
        {
            "name": "r-car",
            "description": "Companion to Applied Regression Functions and Datasets to Accompany J.\nFox and S. Weisberg, An R Companion to Applied Regression, Second\nEdition, Sage, 2011."
        },
        {
            "name": "r-effects",
            "description": "Effect Displays for Linear, Generalized Linear, and Other Models\nGraphical and tabular effect displays, e.g., of interactions, for\nvarious statistical models with linear predictors."
        },
        {
            "name": "r-flexmix",
            "description": "Flexible Mixture Modeling A general framework for finite mixtures of\nregression models using the EM algorithm is implemented. The E-step and\nall data handling are provided, while the M-step can be supplied by the\nuser to easily define new models. Existing drivers implement mixtures of\nstandard linear models, generalized linear models and model-based\nclustering."
        },
        {
            "name": "r-hmisc",
            "description": "Harrell Miscellaneous Contains many functions useful for data analysis,\nhigh-level graphics, utility operations, functions for computing sample\nsize and power, importing and annotating datasets, imputing missing\nvalues, advanced table making, variable clustering, character string\nmanipulation, conversion of R objects to LaTeX and html code, and\nrecoding variables."
        },
        {
            "name": "r-ipred",
            "description": "Improved predictive models by indirect classification and bagging for\nclassification, regression and survival problems as well as resampling\nbased estimators of prediction error."
        }
    ]
}